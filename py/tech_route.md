
# 唐宋八大家作品意象数据可视化项目技术路径

本项目旨在从大规模诗词数据集中筛选出唐宋八大家的作品，进行文本分析以提取核心意象词语，并通过数据可视化直观展示其词频分布。

**数据源格式：** JSON 列表，每个元素包含 `author` (作者)、`paragraphs` (内容段落列表) 等字段。

**主要技术栈：** Python (`json`, `jieba`, `collections`, `pandas`, `matplotlib`, `wordcloud`)

---

## 阶段一：数据准备与筛选

| 步骤 | 目标 | 关键操作 | Python 工具/库 | 备注 |
| :--- | :--- | :--- | :--- | :--- |
| **1.1 加载数据** | 读取原始 JSON 文件。 | 使用 `json.load()` 函数加载数据。 | `json` | 确保文件编码为 `UTF-8`。 |
| **1.2 定义目标作者** | 确定唐宋八大家的精确名单。 | 创建包含所有唐宋八大家姓名的列表（需考虑繁体和简体）。 | Python List | **名单：** 韩愈, 柳宗元, 欧阳修, 苏洵, 苏轼, 苏辙, 曾巩, 王安石 (及其繁体名)。 |
| **1.3 筛选作品** | 提取出目标作者的所有作品。 | 遍历数据集，根据作品的 `author` 字段进行精确匹配。 | Python List Comprehension | 将筛选出的作品保存为新的数据结构，用于后续分析。 |

---

## 阶段二：文本处理与意象提取

| 步骤 | 目标 | 关键操作 | Python 工具/库 | 备注 |
| :--- | :--- | :--- | :--- | :--- |
| **2.1 文本合并** | 将分散的诗词段落整合成一篇完整的文本。 | 遍历每个作品，将 `paragraphs` 列表中的所有字符串连接成一个长字符串。 | Python String Methods | |
| **2.2 词汇切分 (分词)** | 将连续的中文文本切分成词语单元。 | 对合并后的文本使用中文分词工具进行处理。 | `jieba` | 确保分词结果准确。 |
| **2.3 停用词过滤** | 移除不具有实质意义的常用词（如助词、介词）。 | 准备一个中文停用词列表，过滤掉分词结果中包含的停用词。 | Python Set / `jieba` | 提高意象词语的纯度。 |
| **2.4 词性筛选 (意象提取)** | 精确定位具有“意象”特征的词语。 | 使用 `jieba.posseg` 进行词性标注，并**只保留**名词 (n)、人名 (nr)、地名 (ns) 和形容词 (a) 等，以排除动词、副词等。 | `jieba.posseg` | 这是识别“意象”的关键步骤。 |
| **2.5 词频统计** | 计算每个意象词语的出现次数。 | 统计所有过滤后词语的频率。 | `collections.Counter` | |

---

## 阶段三：数据可视化

| 步骤 | 目标 | 关键操作 | Python 工具/库 | 产出物 |
| :--- | :--- | :--- | :--- | :--- |
| **3.1 准备数据** | 将词频统计结果转换为适合绘图的数据格式。 | 将 `Counter` 结果转换为 Pandas DataFrame，包含 `Word` 和 `Frequency` 两列。 | `pandas` | |
| **3.2 柱状图** | 直观展示 Top N 核心意象的精确频率。 | 绘制 Top 20/30 词语的柱状图。 | `matplotlib.pyplot` / `seaborn` | 意象词频排行图。 |
| **3.3 词云图** | 以艺术形式展示所有意象词语的分布权重。 | 基于所有意象的词频数据生成词云图。 | `wordcloud` | 意象词云图 (词越大，频率越高)。 |